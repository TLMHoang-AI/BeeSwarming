{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_data(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_pickle_data(\"Train_stft_features.pkl\")\n",
    "val_data = load_pickle_data(\"Val_stft_features.pkl\")\n",
    "test_data = load_pickle_data(\"Test_stft_features.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM (Support vector machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for Validation Set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "None_swarming       1.00      0.50      0.67      1800\n",
      "     Swarming       0.67      1.00      0.80      1800\n",
      "\n",
      "     accuracy                           0.75      3600\n",
      "    macro avg       0.83      0.75      0.73      3600\n",
      " weighted avg       0.83      0.75      0.73      3600\n",
      "\n",
      "Accuracy: 0.75\n",
      "F1-Score: 0.7333333333333333\n",
      "\n",
      "Classification report for Test Set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "None_swarming       1.00      0.33      0.50      2400\n",
      "     Swarming       0.60      1.00      0.75      2441\n",
      "\n",
      "     accuracy                           0.67      4841\n",
      "    macro avg       0.80      0.67      0.63      4841\n",
      " weighted avg       0.80      0.67      0.63      4841\n",
      "\n",
      "Accuracy (Test): 0.6701094815120843\n",
      "F1-Score (Test): 0.6285257241154586\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kurtosis, skew\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "def extract_features(stft_matrix):\n",
    "    mean_stft = np.mean(stft_matrix, axis=1)\n",
    "    var_stft = np.var(stft_matrix, axis=1)\n",
    "    max_stft = np.max(stft_matrix, axis=1)\n",
    "\n",
    "    return np.concatenate([mean_stft, var_stft, max_stft])\n",
    "\n",
    "X_train, y_train = [], []\n",
    "for item in train_data:\n",
    "    stft = item['stft']\n",
    "    label = item['category']\n",
    "    X_train.append(extract_features(stft))\n",
    "    y_train.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Xử lý dữ liệu Validation\n",
    "X_val, y_val = [], []\n",
    "for item in val_data:\n",
    "    stft = item['stft']\n",
    "    label = item['category']\n",
    "    X_val.append(extract_features(stft))\n",
    "    y_val.append(label)\n",
    "\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "# Huấn luyện SVM với kernel tuyến tính\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán trên tập Validation\n",
    "y_pred = svm_model.predict(X_val)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "print(\"Classification report for Validation Set:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1-Score: {f1}\")\n",
    "\n",
    "# Xử lý dữ liệu Test\n",
    "X_test, y_test = [], []\n",
    "for item in test_data:\n",
    "    stft = item['stft']\n",
    "    label = item['category']\n",
    "    X_test.append(extract_features(stft))\n",
    "    y_test.append(label)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Dự đoán trên tập Test\n",
    "y_test_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Đánh giá mô hình trên tập Test\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "print(\"\\nClassification report for Test Set:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(f\"Accuracy (Test): {accuracy_test}\")\n",
    "print(f\"F1-Score (Test): {f1_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape sau khi PCA (Train): (12600, 771)\n",
      "Shape sau khi PCA (Validation): (3600, 771)\n",
      "Shape sau khi PCA (Test): (4841, 771)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape sau khi PCA (Train): {X_train.shape}\")\n",
    "print(f\"Shape sau khi PCA (Validation): {X_val.shape}\")\n",
    "print(f\"Shape sau khi PCA (Test): {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m explained_variance \u001b[38;5;241m=\u001b[39m \u001b[43mpca\u001b[49m\u001b[38;5;241m.\u001b[39mexplained_variance_ratio_\n\u001b[0;32m      5\u001b[0m cumulative_variance \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcumsum(explained_variance)\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pca' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(1, len(explained_variance) + 1), explained_variance, alpha=0.7, label=\"Phương sai từng thành phần\")\n",
    "plt.xlabel(\"Thành phần chính\")\n",
    "plt.ylabel(\"Tỷ lệ phương sai\")\n",
    "plt.title(\"Tỷ lệ phương sai từng thành phần chính\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--', color='b', label=\"Phương sai tích lũy\")\n",
    "plt.axhline(y=0.95, color='r', linestyle='--', label=\"Ngưỡng 95% phương sai\")\n",
    "plt.xlabel(\"Số thành phần chính\")\n",
    "plt.ylabel(\"Tỷ lệ phương sai tích lũy\")\n",
    "plt.title(\"Phương sai tích lũy theo số thành phần chính\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Số lượng đặc trưng của mỗi mẫu trong tập huấn luyện:\", X_train.shape[1])\n",
    "print(\"Số lượng đặc trưng của mỗi mẫu trong tập validation:\", X_val.shape[1])\n",
    "print(\"Số lượng đặc trưng của mỗi mẫu trong tập test:\", X_test.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape sau khi PCA (Train): (12600, 400)\n",
      "Shape sau khi PCA (Validation): (3600, 400)\n",
      "Shape sau khi PCA (Test): (4841, 400)\n"
     ]
    }
   ],
   "source": [
    "n_components = 400\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_val_pca = pca.transform(X_val)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(f\"Shape sau khi PCA (Train): {X_train_pca.shape}\")\n",
    "print(f\"Shape sau khi PCA (Validation): {X_val_pca.shape}\")\n",
    "print(f\"Shape sau khi PCA (Test): {X_test_pca.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.75\n",
      "Test Accuracy: 0.6701094815120843\n"
     ]
    }
   ],
   "source": [
    "# Huấn luyện SVM với dữ liệu đã giảm chiều\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Đánh giá trên tập Validation\n",
    "y_val_pred = svm_model.predict(X_val_pca)\n",
    "accuracy_val = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy: {accuracy_val}\")\n",
    "\n",
    "# Đánh giá trên tập Test\n",
    "y_test_pred = svm_model.predict(X_test_pca)\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Test Accuracy: {accuracy_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng đặc trưng của mỗi mẫu trong tập huấn luyện: 771\n",
      "Số lượng đặc trưng của mỗi mẫu trong tập validation: 771\n",
      "Số lượng đặc trưng của mỗi mẫu trong tập test: 771\n"
     ]
    }
   ],
   "source": [
    "print(\"Số lượng đặc trưng của mỗi mẫu trong tập huấn luyện:\", X_train.shape[1])\n",
    "print(\"Số lượng đặc trưng của mỗi mẫu trong tập validation:\", X_val.shape[1])\n",
    "print(\"Số lượng đặc trưng của mỗi mẫu trong tập test:\", X_test.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN (K-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "5\n",
      "7\n",
      "9\n",
      "11\n",
      "13\n",
      "15\n",
      "17\n",
      "19\n",
      "21\n",
      "23\n",
      "25\n",
      "27\n",
      "29\n",
      "31\n",
      "33\n",
      "35\n",
      "37\n",
      "39\n",
      "41\n",
      "43\n",
      "45\n",
      "47\n",
      "49\n",
      "51\n",
      "53\n",
      "55\n",
      "57\n",
      "59\n",
      "61\n",
      "63\n",
      "65\n",
      "67\n",
      "69\n",
      "71\n",
      "73\n",
      "75\n",
      "77\n",
      "79\n",
      "81\n",
      "83\n",
      "85\n",
      "87\n",
      "89\n",
      "91\n",
      "93\n",
      "95\n",
      "97\n",
      "99\n",
      "101\n",
      "103\n",
      "105\n",
      "107\n",
      "109\n",
      "111\n",
      "113\n",
      "115\n",
      "117\n",
      "119\n",
      "121\n",
      "123\n",
      "125\n",
      "127\n",
      "129\n",
      "131\n",
      "133\n",
      "135\n",
      "137\n",
      "139\n",
      "141\n",
      "143\n",
      "145\n",
      "147\n",
      "Best k: 117 with F1-score: 0.6914219487324557\n"
     ]
    }
   ],
   "source": [
    "best_k = None\n",
    "best_f1 = 0\n",
    "results = []\n",
    "\n",
    "for k in range(1, 149, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    y_val_pred = knn.predict(X_val)\n",
    "    f1_val = f1_score(y_val, y_val_pred, average='weighted')\n",
    "\n",
    "    results.append((k, f1_val))\n",
    "    print(k)\n",
    "    if f1_val > best_f1:\n",
    "        best_f1 = f1_val\n",
    "        best_k = k\n",
    "\n",
    "print(f\"Best k: {best_k} with F1-score: {best_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for Validation Set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "None_swarming       0.83      0.51      0.63      1800\n",
      "     Swarming       0.65      0.90      0.75      1800\n",
      "\n",
      "     accuracy                           0.70      3600\n",
      "    macro avg       0.74      0.70      0.69      3600\n",
      " weighted avg       0.74      0.70      0.69      3600\n",
      "\n",
      "Accuracy on Validation Set (KNN): 0.7030555555555555\n",
      "F1-Score on Validation Set (KNN): 0.6914219487324557\n",
      "Classification report for Test Set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "None_swarming       0.95      0.33      0.49      2400\n",
      "     Swarming       0.60      0.98      0.74      2441\n",
      "\n",
      "     accuracy                           0.66      4841\n",
      "    macro avg       0.77      0.66      0.62      4841\n",
      " weighted avg       0.77      0.66      0.62      4841\n",
      "\n",
      "Accuracy on Test Set (KNN): 0.6610204503201818\n",
      "F1-Score on Test Set (KNN): 0.6208596432922614\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=117)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred_knn = knn_model.predict(X_val)\n",
    "\n",
    "print(\"Classification report for Validation Set:\")\n",
    "print(classification_report(y_val, y_val_pred_knn))\n",
    "\n",
    "accuracy_val_knn = accuracy_score(y_val, y_val_pred_knn)\n",
    "f1_val_knn = f1_score(y_val, y_val_pred_knn, average='weighted')\n",
    "\n",
    "print(f\"Accuracy on Validation Set (KNN): {accuracy_val_knn}\")\n",
    "print(f\"F1-Score on Validation Set (KNN): {f1_val_knn}\")\n",
    "\n",
    "y_test_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "print(\"Classification report for Test Set:\")\n",
    "print(classification_report(y_test, y_test_pred_knn))\n",
    "\n",
    "accuracy_test_knn = accuracy_score(y_test, y_test_pred_knn)\n",
    "f1_test_knn = f1_score(y_test, y_test_pred_knn, average='weighted')\n",
    "\n",
    "print(f\"Accuracy on Test Set (KNN): {accuracy_test_knn}\")\n",
    "print(f\"F1-Score on Test Set (KNN): {f1_test_knn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for Validation Set (KNN - PCA):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "None_swarming       0.80      0.52      0.63      1800\n",
      "     Swarming       0.64      0.87      0.74      1800\n",
      "\n",
      "     accuracy                           0.70      3600\n",
      "    macro avg       0.72      0.70      0.69      3600\n",
      " weighted avg       0.72      0.70      0.69      3600\n",
      "\n",
      "Accuracy on Validation Set (KNN - PCA): 0.6955555555555556\n",
      "F1-Score on Validation Set (KNN - PCA): 0.685747382183941\n",
      "Classification report for Test Set (KNN - PCA):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "None_swarming       0.92      0.33      0.49      2400\n",
      "     Swarming       0.60      0.97      0.74      2441\n",
      "\n",
      "     accuracy                           0.66      4841\n",
      "    macro avg       0.76      0.65      0.61      4841\n",
      " weighted avg       0.76      0.66      0.62      4841\n",
      "\n",
      "Accuracy on Test Set (KNN - PCA): 0.6550299524891552\n",
      "F1-Score on Test Set (KNN - PCA): 0.6158241931260705\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Áp dụng KNN sau PCA\n",
    "knn_model_pca = KNeighborsClassifier(n_neighbors=51)\n",
    "knn_model_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "# Dự đoán trên tập Validation\n",
    "y_val_pred_knn_pca = knn_model_pca.predict(X_val_pca)\n",
    "\n",
    "print(\"Classification report for Validation Set (KNN - PCA):\")\n",
    "print(classification_report(y_val, y_val_pred_knn_pca))\n",
    "\n",
    "accuracy_val_knn_pca = accuracy_score(y_val, y_val_pred_knn_pca)\n",
    "f1_val_knn_pca = f1_score(y_val, y_val_pred_knn_pca, average='weighted')\n",
    "\n",
    "print(f\"Accuracy on Validation Set (KNN - PCA): {accuracy_val_knn_pca}\")\n",
    "print(f\"F1-Score on Validation Set (KNN - PCA): {f1_val_knn_pca}\")\n",
    "\n",
    "# Dự đoán trên tập Test\n",
    "y_test_pred_knn_pca = knn_model_pca.predict(X_test_pca)\n",
    "\n",
    "print(\"Classification report for Test Set (KNN - PCA):\")\n",
    "print(classification_report(y_test, y_test_pred_knn_pca))\n",
    "\n",
    "accuracy_test_knn_pca = accuracy_score(y_test, y_test_pred_knn_pca)\n",
    "f1_test_knn_pca = f1_score(y_test, y_test_pred_knn_pca, average='weighted')\n",
    "\n",
    "print(f\"Accuracy on Test Set (KNN - PCA): {accuracy_test_knn_pca}\")\n",
    "print(f\"F1-Score on Test Set (KNN - PCA): {f1_test_knn_pca}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB (Naive Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for Validation Set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "None_swarming       1.00      0.25      0.40      1800\n",
      "     Swarming       0.57      1.00      0.73      1800\n",
      "\n",
      "     accuracy                           0.62      3600\n",
      "    macro avg       0.79      0.62      0.56      3600\n",
      " weighted avg       0.79      0.62      0.56      3600\n",
      "\n",
      "Accuracy: 0.6241666666666666\n",
      "F1-Score: 0.5623480206598905\n",
      "\n",
      "Classification report for Test Set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "None_swarming       1.00      0.33      0.50      2400\n",
      "     Swarming       0.60      1.00      0.75      2441\n",
      "\n",
      "     accuracy                           0.67      4841\n",
      "    macro avg       0.80      0.67      0.63      4841\n",
      " weighted avg       0.80      0.67      0.63      4841\n",
      "\n",
      "Accuracy (Test): 0.6701094815120843\n",
      "F1-Score (Test): 0.6285257241154586\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for item in train_data:\n",
    "    stft = item['stft'].flatten()\n",
    "    label = item['category']\n",
    "\n",
    "    X_train.append(stft)\n",
    "    y_train.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "for item in val_data:\n",
    "    stft = item['stft'].flatten()\n",
    "    label = item['category']\n",
    "\n",
    "    X_val.append(stft)\n",
    "    y_val.append(label)\n",
    "\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = nb_model.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "print(\"Classification report for Validation Set:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1-Score: {f1}\")\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for item in test_data:\n",
    "    stft = item['stft'].flatten()\n",
    "    label = item['category']\n",
    "\n",
    "    X_test.append(stft)\n",
    "    y_test.append(label)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "y_test_pred = nb_model.predict(X_test)\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "print(\"\\nClassification report for Test Set:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "print(f\"Accuracy (Test): {accuracy_test}\")\n",
    "print(f\"F1-Score (Test): {f1_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest(RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for Validation Set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "None_swarming       1.00      0.41      0.59      1800\n",
      "     Swarming       0.63      1.00      0.77      1800\n",
      "\n",
      "     accuracy                           0.71      3600\n",
      "    macro avg       0.82      0.71      0.68      3600\n",
      " weighted avg       0.82      0.71      0.68      3600\n",
      "\n",
      "Accuracy: 0.7072222222222222\n",
      "F1-Score: 0.6797727149204108\n",
      "\n",
      "Classification report for Test Set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "None_swarming       1.00      0.33      0.50      2400\n",
      "     Swarming       0.60      1.00      0.75      2441\n",
      "\n",
      "     accuracy                           0.67      4841\n",
      "    macro avg       0.80      0.67      0.63      4841\n",
      " weighted avg       0.80      0.67      0.63      4841\n",
      "\n",
      "Accuracy (Test): 0.6701094815120843\n",
      "F1-Score (Test): 0.6285257241154586\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for item in train_data:\n",
    "    stft = item['stft'].flatten()\n",
    "    label = item['category']\n",
    "\n",
    "    X_train.append(stft)\n",
    "    y_train.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "for item in val_data:\n",
    "    stft = item['stft'].flatten()\n",
    "    label = item['category']\n",
    "\n",
    "    X_val.append(stft)\n",
    "    y_val.append(label)\n",
    "\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "print(\"Classification report for Validation Set:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1-Score: {f1}\")\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for item in test_data:\n",
    "    stft = item['stft'].flatten()\n",
    "    label = item['category']\n",
    "\n",
    "    X_test.append(stft)\n",
    "    y_test.append(label)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "print(\"\\nClassification report for Test Set:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "print(f\"Accuracy (Test): {accuracy_test}\")\n",
    "print(f\"F1-Score (Test): {f1_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting, GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for item in train_data:\n",
    "    stft = item['stft'].flatten()\n",
    "    label = item['category']\n",
    "\n",
    "    X_train.append(stft)\n",
    "    y_train.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "for item in val_data:\n",
    "    stft = item['stft'].flatten()\n",
    "    label = item['category']\n",
    "\n",
    "    X_val.append(stft)\n",
    "    y_val.append(label)\n",
    "\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=50,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42\n",
    ")\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gb_model.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "print(\"Classification report for Validation Set:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1-Score: {f1}\")\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for item in test_data:\n",
    "    stft = item['stft'].flatten()\n",
    "    label = item['category']\n",
    "\n",
    "    X_test.append(stft)\n",
    "    y_test.append(label)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "y_test_pred = gb_model.predict(X_test)\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "print(\"\\nClassification report for Test Set:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "print(f\"Accuracy (Test): {accuracy_test}\")\n",
    "print(f\"F1-Score (Test): {f1_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
